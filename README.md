## Milk production prediction using RNN

Recurrent neural networks differ from the traditional feed-forward neural networks in many ways. This difference, in the addition of complexity, stems with the promise of new behaviours which the traditional methods are limited in achieving. ``A recurrent network whose inputs are not fixed but rather constitute an input sequence can be used to transform an input sequence into an output sequence while taking into account contextual information in a flexible way.'' (Yoshua Bengio, et. at. 1994.) The  classes  of  neural network  that  predict  the future  values based on past sequence of observations is known as Recurrent Neural Network, of such  type make use of previous stages to learn of data and forecast futures trends. RNN  can’t  store  long  time  memory,  so  the  use  of  the  Long  Short-Term  Memory  (LSTM)  based  on  “memory  line” proved to be very useful in forecasting cases with long time data. In a LSTM the memorisation of earlier stages can  be  performed  trough  gates  with  along  memory  line  incorporated.

Long Short-Term Memory is a family of Recurrent Neural Network RNN, it’s also capable of catching data from past stages and use it for future predictions (Patterson J., 2017.) It is a recurrent network because of the feedback connections in its architecture. It has an advantage over traditional neural networks due to its capability to process the entire sequence of data. Its architecture comprises the cell, input gate, output gate and forget gate. LSTMs are designed to learn order dependence in sequence prediction problems. The cell remembers values over arbitrary time intervals, and the three gates regulate the flow of information into and out of the cell. The cell of the model is responsible for keeping track of the dependencies between the elements in the input sequence. The input gate controls the extent to which a new value flows into the cell, the forget gate controls the extent to which a value remains in the cell, and the output gate controls the extent to which the value in the cell is used to compute the output activation of the LSTM unit.\\
